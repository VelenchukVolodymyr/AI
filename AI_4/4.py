import io
import os

from PIL import Image
import streamlit as st
import numpy as np
import cv2


class Perceptron:
    def __init__(self, input_size, learning_rate=0.1):
        self.weights = np.random.uniform(-0.5, 0.5, input_size + 1)  # +1 –¥–ª—è bias
        self.learning_rate = learning_rate
        self.errors = []

    def predict(self, inputs):
        inputs_with_bias = np.insert(inputs, 0, 1)
        summation = np.dot(inputs_with_bias, self.weights)
        return 1 if summation >= 0 else 0

    def train(self, inputs, target):
        inputs_with_bias = np.insert(inputs, 0, 1)
        prediction = self.predict(inputs)
        error = target - prediction

        if error != 0:
            self.weights += self.learning_rate * error * inputs_with_bias

        self.errors.append(error)
        return error


class MultiClassPerceptronSystem:
    def __init__(self):
        self.perceptrons = []
        self.training_data = {'–ö–≤–∞–¥—Ä–∞—Ç': [], '–ö–æ–ª–æ': [], '–†–æ–º–±': []}
        self.trained = False
        self.feature_size = 0

    def add_training_data(self, class_name, features):
        self.training_data[class_name].append(features)

    def train_perceptrons(self, learning_rate=0.1):
        # –ó–Ω–∞—Ö–æ–¥–∏–º–æ –º—ñ–Ω—ñ–º–∞–ª—å–Ω—É –∫—ñ–ª—å–∫—ñ—Å—Ç—å –∑—Ä–∞–∑–∫—ñ–≤ —Å–µ—Ä–µ–¥ –∫–ª–∞—Å—ñ–≤
        min_samples = min(len(self.training_data[cls]) for cls in self.training_data)

        if min_samples == 0:
            raise ValueError("–£—Å—ñ –∫–ª–∞—Å–∏ –ø–æ–≤–∏–Ω–Ω—ñ –º–∞—Ç–∏ –ø—Ä–∏–Ω–∞–π–º–Ω—ñ –æ–¥–∏–Ω –∑—Ä–∞–∑–æ–∫")

        # –í–∏–∑–Ω–∞—á–∞—î–º–æ —Ä–æ–∑–º—ñ—Ä–Ω—ñ—Å—Ç—å –æ–∑–Ω–∞–∫
        self.feature_size = len(self.training_data['–ö–≤–∞–¥—Ä–∞—Ç'][0])

        # –°—Ç–≤–æ—Ä—é—î–º–æ —Ç—Ä–∏ –ø–µ—Ä—Ü–µ–ø—Ç—Ä–æ–Ω–∏ (–æ–¥–∏–Ω –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ –∫–ª–∞—Å—É)
        self.perceptrons = [Perceptron(self.feature_size, learning_rate) for _ in range(3)]

        # –ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–∏—Ö –¥–ª—è –Ω–∞–≤—á–∞–Ω–Ω—è
        training_data = []
        for i, (class_name, samples) in enumerate(self.training_data.items()):
            for sample in samples[:min_samples]:  # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –æ–¥–Ω–∞–∫–æ–≤—É –∫—ñ–ª—å–∫—ñ—Å—Ç—å –∑—Ä–∞–∑–∫—ñ–≤
                training_data.append((sample, i, class_name))

        # –ù–∞–≤—á–∞–Ω–Ω—è –∫–æ–∂–Ω–æ–≥–æ –ø–µ—Ä—Ü–µ–ø—Ç—Ä–æ–Ω–∞
        convergence = [False, False, False]
        epochs = 100

        for epoch in range(epochs):
            for perceptron_idx in range(3):
                if convergence[perceptron_idx]:
                    continue

                total_error = 0
                for features, target_class, _ in training_data:
                    # –î–ª—è –∫–æ–∂–Ω–æ–≥–æ –ø–µ—Ä—Ü–µ–ø—Ç—Ä–æ–Ω–∞: 1 —è–∫—â–æ –π–æ–≥–æ –∫–ª–∞—Å, 0 —è–∫—â–æ —ñ–Ω—à–∏–π
                    target = 1 if target_class == perceptron_idx else 0
                    error = self.perceptrons[perceptron_idx].train(features, target)
                    total_error += abs(error)

                if total_error == 0:
                    convergence[perceptron_idx] = True

        self.trained = True
        return all(convergence)

    def predict(self, features):
        if not self.trained:
            raise ValueError("–°–∏—Å—Ç–µ–º–∞ –Ω–µ –Ω–∞–≤—á–µ–Ω–∞")

        scores = []
        for i, perceptron in enumerate(self.perceptrons):
            inputs_with_bias = np.insert(features, 0, 1)
            score = np.dot(inputs_with_bias, perceptron.weights)
            scores.append(score)

        class_names = ['–ö–≤–∞–¥—Ä–∞—Ç', '–ö–æ–ª–æ', '–†–æ–º–±']
        winning_class = class_names[np.argmax(scores)]

        return winning_class, scores


def extract_features(image_array, grid_size):
    """–í–∏–¥–æ–±—É–≤–∞—î –∞–±—Å–æ–ª—é—Ç–Ω–∏–π —Ç–∞ –Ω–æ—Ä–º–æ–≤–∞–Ω–∏–π –≤–µ–∫—Ç–æ—Ä–∏ –æ–∑–Ω–∞–∫"""
    _, binary_image = cv2.threshold(image_array, 128, 255, cv2.THRESH_BINARY)

    rows, cols = map(int, grid_size.split('x'))
    img_height, img_width = binary_image.shape
    cell_height = img_height // rows
    cell_width = img_width // cols

    absolute_vector = []

    for i in range(rows):
        for j in range(cols):
            y_start = i * cell_height
            y_end = (i + 1) * cell_height if i < rows - 1 else img_height
            x_start = j * cell_width
            x_end = (j + 1) * cell_width if j < cols - 1 else img_width

            cell = binary_image[y_start:y_end, x_start:x_end]
            black_pixels = np.sum(cell == 0)
            absolute_vector.append(black_pixels)

    total_sum = sum(absolute_vector)
    if total_sum > 0:
        normalized_vector = [val / total_sum for val in absolute_vector]
    else:
        normalized_vector = [0 for _ in absolute_vector]

    return absolute_vector, normalized_vector, binary_image


def create_grid_image(binary_image, grid_size):
    """–°—Ç–≤–æ—Ä—é—î –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –∑ –Ω–∞–∫–ª–∞–¥–µ–Ω–æ—é —Å—ñ—Ç–∫–æ—é"""
    grid_image = cv2.cvtColor(binary_image, cv2.COLOR_GRAY2BGR)
    rows, cols = map(int, grid_size.split('x'))
    img_height, img_width = binary_image.shape
    cell_height = img_height // rows
    cell_width = img_width // cols

    for i in range(rows):
        for j in range(cols):
            y_start = i * cell_height
            y_end = (i + 1) * cell_height if i < rows - 1 else img_height
            x_start = j * cell_width
            x_end = (j + 1) * cell_width if j < cols - 1 else img_width

            if j > 0:
                cv2.line(grid_image, (x_start, 0), (x_start, img_height), (0, 0, 255), 2)
            if i > 0:
                cv2.line(grid_image, (0, y_start), (img_width, y_start), (0, 0, 255), 2)

    cv2.rectangle(grid_image, (0, 0), (img_width - 1, img_height - 1), (0, 255, 0), 2)
    return grid_image


def load_images_from_folder(folder_path, class_name, max_images=10):
    """–ó–∞–≤–∞–Ω—Ç–∞–∂—É—î –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –∑ –ø–∞–ø–∫–∏"""
    images = []
    if os.path.exists(folder_path):
        for filename in os.listdir(folder_path):
            if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp')):
                # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ, —á–∏ –º—ñ—Å—Ç–∏—Ç—å –Ω–∞–∑–≤–∞ —Ñ–∞–π–ª—É —ñ–º'—è –∫–ª–∞—Å—É
                if class_name.lower() in filename.lower():
                    try:
                        img_path = os.path.join(folder_path, filename)
                        pil_image = Image.open(img_path)
                        images.append((pil_image, filename))
                        if len(images) >= max_images:
                            break
                    except Exception as e:
                        st.error(f"–ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è {filename}: {str(e)}")
    return images


# –û—Å–Ω–æ–≤–Ω–∞ –ø—Ä–æ–≥—Ä–∞–º–∞
st.set_page_config(page_title="–ü–µ—Ä—Ü–µ–ø—Ç—Ä–æ–Ω–Ω–∞ —Å–∏—Å—Ç–µ–º–∞ —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è", layout="wide")
st.write("# –°–∏—Å—Ç–µ–º–∞ —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è –ø–µ—Ä—Ü–µ–ø—Ç—Ä–æ–Ω–Ω–æ–≥–æ —Ç–∏–ø—É")

# –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è —Å–∏—Å—Ç–µ–º–∏
if 'perceptron_system' not in st.session_state:
    st.session_state.perceptron_system = MultiClassPerceptronSystem()

# –í–∏–±—ñ—Ä –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤
col1, col2, col3 = st.columns(3)
with col1:
    grid_size = st.selectbox("–†–æ–∑–º—ñ—Ä —Å—ñ—Ç–∫–∏:", ["3x3", "4x4", "5x5", "6x6", "4x5", "5x4"], index=2)
with col2:
    learning_rate = st.slider("–®–≤–∏–¥–∫—ñ—Å—Ç—å –Ω–∞–≤—á–∞–Ω–Ω—è:", 0.01, 1.0, 0.1, 0.01)
with col3:
    # –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ –≤—Å—Ç–∞–Ω–æ–≤–ª—é—î–º–æ —à–ª—è—Ö –¥–æ –ø–∞–ø–∫–∏ img
    folder_path = st.text_input("–®–ª—è—Ö –¥–æ –ø–∞–ø–∫–∏ –∑ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è–º–∏:", value="./img")

# –í–∫–ª–∞–¥–∫–∏ –¥–ª—è —Ä—ñ–∑–Ω–∏—Ö —Ñ—É–Ω–∫—Ü—ñ–π
tab1, tab2, tab3, tab4 = st.tabs(["–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö", "–ü–µ—Ä–µ–≥–ª—è–¥ –æ–∑–Ω–∞–∫", "–ù–∞–≤—á–∞–Ω–Ω—è", "–¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è"])

with tab1:
    st.header("–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –Ω–∞–≤—á–∞–ª—å–Ω–∏—Ö –¥–∞–Ω–∏—Ö")

    # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —ñ—Å–Ω—É–≤–∞–Ω–Ω—è –ø–∞–ø–∫–∏
    if not os.path.exists(folder_path):
        st.error(f"–ü–∞–ø–∫–∞ '{folder_path}' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–∞! –ü–µ—Ä–µ–≤—ñ—Ä—Ç–µ —à–ª—è—Ö.")
    else:
        st.success(f"–ü–∞–ø–∫–∞ '{folder_path}' –∑–Ω–∞–π–¥–µ–Ω–∞. –§–∞–π–ª–∏ –≤ –ø–∞–ø—Ü—ñ:")
        try:
            files = os.listdir(folder_path)
            image_files = [f for f in files if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp'))]
            st.write(f"–ó–Ω–∞–π–¥–µ–Ω–æ {len(image_files)} –∑–æ–±—Ä–∞–∂–µ–Ω—å:")
            for file in image_files:
                st.write(f"- {file}")
        except Exception as e:
            st.error(f"–ü–æ–º–∏–ª–∫–∞ —á–∏—Ç–∞–Ω–Ω—è –ø–∞–ø–∫–∏: {str(e)}")

    if st.button("–ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –∑ –ø–∞–ø–∫–∏"):
        with st.spinner("–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∑–æ–±—Ä–∞–∂–µ–Ω—å..."):
            # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ –∫–ª–∞—Å—É
            classes = ['–ö–≤–∞–¥—Ä–∞—Ç', '–ö–æ–ª–æ', '–†–æ–º–±']

            total_loaded = 0
            for class_name in classes:
                images = load_images_from_folder(folder_path, class_name)

                if images:
                    st.success(f"–ó–Ω–∞–π–¥–µ–Ω–æ {len(images)} –∑–æ–±—Ä–∞–∂–µ–Ω—å –¥–ª—è –∫–ª–∞—Å—É '{class_name}'")

                    # –û–±—Ä–æ–±–∫–∞ –∫–æ–∂–Ω–æ–≥–æ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è
                    for pil_image, filename in images:
                        try:
                            image_array = np.array(pil_image.convert('L'))
                            absolute_vector, normalized_vector, binary_image = extract_features(image_array, grid_size)

                            # –î–æ–¥–∞—î–º–æ –¥–æ –Ω–∞–≤—á–∞–ª—å–Ω–∏—Ö –¥–∞–Ω–∏—Ö
                            st.session_state.perceptron_system.add_training_data(class_name, normalized_vector)
                            total_loaded += 1

                        except Exception as e:
                            st.error(f"–ü–æ–º–∏–ª–∫–∞ –æ–±—Ä–æ–±–∫–∏ {filename}: {str(e)}")
                else:
                    st.warning(f"–ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ –∑–æ–±—Ä–∞–∂–µ–Ω—å –¥–ª—è –∫–ª–∞—Å—É '{class_name}' –≤ –ø–∞–ø—Ü—ñ {folder_path}")

            st.success(f"–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ {total_loaded} –∑–æ–±—Ä–∞–∂–µ–Ω—å –¥–ª—è –Ω–∞–≤—á–∞–Ω–Ω—è")

with tab2:
    st.header("–ü–µ—Ä–µ–≥–ª—è–¥ –≤–µ–∫—Ç–æ—Ä—ñ–≤ –æ–∑–Ω–∞–∫")

    if st.button("–ü–æ–∫–∞–∑–∞—Ç–∏ –≤—Å—ñ –≤–µ–∫—Ç–æ—Ä–∏ –æ–∑–Ω–∞–∫"):
        for class_name in ['–ö–≤–∞–¥—Ä–∞—Ç', '–ö–æ–ª–æ', '–†–æ–º–±']:
            if st.session_state.perceptron_system.training_data[class_name]:
                st.subheader(f"üéØ –ö–ª–∞—Å: {class_name}")
                st.write(f"**–ö—ñ–ª—å–∫—ñ—Å—Ç—å –∑—Ä–∞–∑–∫—ñ–≤:** {len(st.session_state.perceptron_system.training_data[class_name])}")

                # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –≤—Å—ñ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è —Ü—å–æ–≥–æ –∫–ª–∞—Å—É
                all_images = load_images_from_folder(folder_path, class_name, 100)  # –ë–µ—Ä–µ–º–æ –≤—Å—ñ

                if all_images:
                    # –í—ñ–¥–æ–±—Ä–∞–∂–∞—î–º–æ –≤—Å—ñ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –∫–ª–∞—Å—É
                    st.write("### –í—Å—ñ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –∫–ª–∞—Å—É:")

                    # –°—Ç–≤–æ—Ä—é—î–º–æ —Å—ñ—Ç–∫—É –¥–ª—è –≤—ñ–¥–æ–±—Ä–∞–∂–µ–Ω–Ω—è –∑–æ–±—Ä–∞–∂–µ–Ω—å
                    num_images = len(all_images)
                    cols_per_row = 3  # –ö—ñ–ª—å–∫—ñ—Å—Ç—å –∑–æ–±—Ä–∞–∂–µ–Ω—å –≤ —Ä—è–¥–∫—É

                    for i in range(0, num_images, cols_per_row):
                        cols = st.columns(cols_per_row)
                        for j in range(cols_per_row):
                            if i + j < num_images:
                                pil_image, filename = all_images[i + j]
                                with cols[j]:
                                    st.image(pil_image, caption=filename, use_column_width=True)

                    st.write("---")

                    # –í—ñ–¥–æ–±—Ä–∞–∂–∞—î–º–æ –≤–µ–∫—Ç–æ—Ä–∏ –æ–∑–Ω–∞–∫ –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è
                    st.write("### –í–µ–∫—Ç–æ—Ä–∏ –æ–∑–Ω–∞–∫ –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è:")

                    for idx, (pil_image, filename) in enumerate(all_images, 1):
                        st.write(f"#### –ó–æ–±—Ä–∞–∂–µ–Ω–Ω—è {idx}: {filename}")

                        # –û–±—Ä–æ–±–∫–∞ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –¥–ª—è –æ—Ç—Ä–∏–º–∞–Ω–Ω—è –æ–∑–Ω–∞–∫
                        image_array = np.array(pil_image.convert('L'))
                        absolute_vector, normalized_vector, binary_image = extract_features(image_array, grid_size)
                        grid_image = create_grid_image(binary_image, grid_size)

                        col1, col2 = st.columns(2)
                        with col1:
                            st.image(pil_image, caption="–û—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–µ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è", use_column_width=True)
                        with col2:
                            st.image(grid_image, caption=f"–°–µ–≥–º–µ–Ω—Ç–∞—Ü—ñ—è ({grid_size})", use_column_width=True)

                        # –í—ñ–¥–æ–±—Ä–∞–∂–∞—î–º–æ –≤–µ–∫—Ç–æ—Ä–∏
                        col3, col4 = st.columns(2)
                        with col3:
                            st.write("**–ê–±—Å–æ–ª—é—Ç–Ω–∏–π –≤–µ–∫—Ç–æ—Ä –æ–∑–Ω–∞–∫:**")
                            st.text_area(f"–ê–±—Å–æ–ª—é—Ç–Ω—ñ –∑–Ω–∞—á–µ–Ω–Ω—è {idx}",
                                         "; ".join([f"{val}" for val in absolute_vector]),
                                         height=100, key=f"abs_{class_name}_{idx}")

                        with col4:
                            st.write("**–ù–æ—Ä–º–æ–≤–∞–Ω–∏–π –≤–µ–∫—Ç–æ—Ä –æ–∑–Ω–∞–∫:**")
                            st.text_area(f"–ù–æ—Ä–º–æ–≤–∞–Ω—ñ –∑–Ω–∞—á–µ–Ω–Ω—è {idx}",
                                         "; ".join([f"{val:.6f}" for val in normalized_vector]),
                                         height=100, key=f"norm_{class_name}_{idx}")

                        st.write("---")

                else:
                    st.warning(f"–ù–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –¥–ª—è –∫–ª–∞—Å—É '{class_name}'")
            else:
                st.warning(f"–ù–µ–º–∞—î –¥–∞–Ω–∏—Ö –¥–ª—è –∫–ª–∞—Å—É '{class_name}'")

        # –ó–∞–≥–∞–ª—å–Ω–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        st.subheader("üìä –ó–∞–≥–∞–ª—å–Ω–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞")
        total_samples = sum(len(st.session_state.perceptron_system.training_data[cls])
                            for cls in ['–ö–≤–∞–¥—Ä–∞—Ç', '–ö–æ–ª–æ', '–†–æ–º–±'])
        st.write(f"**–í—Å—å–æ–≥–æ –∑—Ä–∞–∑–∫—ñ–≤ —É —Å–∏—Å—Ç–µ–º—ñ:** {total_samples}")

        for class_name in ['–ö–≤–∞–¥—Ä–∞—Ç', '–ö–æ–ª–æ', '–†–æ–º–±']:
            count = len(st.session_state.perceptron_system.training_data[class_name])
            st.write(f"- {class_name}: {count} –∑—Ä–∞–∑–∫—ñ–≤")

with tab3:
    st.header("–ù–∞–≤—á–∞–Ω–Ω—è –ø–µ—Ä—Ü–µ–ø—Ç—Ä–æ–Ω—ñ–≤")

    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–∞–Ω–∏—Ö
    st.subheader("–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –Ω–∞–≤—á–∞–ª—å–Ω–∏—Ö –¥–∞–Ω–∏—Ö")
    total_samples = 0
    for class_name in ['–ö–≤–∞–¥—Ä–∞—Ç', '–ö–æ–ª–æ', '–†–æ–º–±']:
        count = len(st.session_state.perceptron_system.training_data[class_name])
        total_samples += count
        st.write(f"{class_name}: {count} –∑—Ä–∞–∑–∫—ñ–≤")

    st.write(f"**–í—Å—å–æ–≥–æ –∑—Ä–∞–∑–∫—ñ–≤:** {total_samples}")

    if total_samples == 0:
        st.error("–ù–µ–º–∞—î –¥–∞–Ω–∏—Ö –¥–ª—è –Ω–∞–≤—á–∞–Ω–Ω—è. –°–ø–æ—á–∞—Ç–∫—É –∑–∞–≤–∞–Ω—Ç–∞–∂—Ç–µ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è.")
    else:
        if st.button("–ü–æ—á–∞—Ç–∏ –Ω–∞–≤—á–∞–Ω–Ω—è"):
            try:
                with st.spinner("–ù–∞–≤—á–∞–Ω–Ω—è..."):
                    success = st.session_state.perceptron_system.train_perceptrons(learning_rate)

                if success:
                    st.success("–ù–∞–≤—á–∞–Ω–Ω—è —É—Å–ø—ñ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")

                    # –ü–æ–∫–∞–∑—É—î–º–æ –≤–∞–≥–∏ –ø–µ—Ä—Ü–µ–ø—Ç—Ä–æ–Ω—ñ–≤
                    st.subheader("–í–∞–≥–∏ –ø–µ—Ä—Ü–µ–ø—Ç—Ä–æ–Ω—ñ–≤")
                    class_names = ['–ö–≤–∞–¥—Ä–∞—Ç', '–ö–æ–ª–æ', '–†–æ–º–±']

                    for i, (perceptron, class_name) in enumerate(
                            zip(st.session_state.perceptron_system.perceptrons, class_names)):
                        st.write(f"**{class_name} –ø–µ—Ä—Ü–µ–ø—Ç—Ä–æ–Ω:**")
                        st.write(f"Bias (w‚ÇÄ): {perceptron.weights[0]:.4f}")
                        for j, weight in enumerate(perceptron.weights[1:], 1):
                            st.write(f"w{j}: {weight:.4f}")
                        st.write("---")



            except Exception as e:
                st.error(f"–ü–æ–º–∏–ª–∫–∞ –Ω–∞–≤—á–∞–Ω–Ω—è: {str(e)}")

with tab4:
    st.header("–¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è —Å–∏—Å—Ç–µ–º–∏")

    if not st.session_state.perceptron_system.trained:
        st.error("–°–ø–æ—á–∞—Ç–∫—É –ø—Ä–æ–≤–µ–¥—ñ—Ç—å –Ω–∞–≤—á–∞–Ω–Ω—è –ø–µ—Ä—Ü–µ–ø—Ç—Ä–æ–Ω—ñ–≤!")
    else:
        # –°–ø–æ—Å—ñ–± 1: –í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è —ñ—Å–Ω—É—é—á–∏—Ö –∑–æ–±—Ä–∞–∂–µ–Ω—å –¥–ª—è —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è
        st.subheader("–¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è –Ω–∞ —ñ—Å–Ω—É—é—á–∏—Ö –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è—Ö")
        test_class = st.selectbox("–û–±–µ—Ä—ñ—Ç—å –∫–ª–∞—Å –¥–ª—è —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è:", ['–ö–≤–∞–¥—Ä–∞—Ç', '–ö–æ–ª–æ', '–†–æ–º–±'])

        # –ó–Ω–∞—Ö–æ–¥–∏–º–æ –¥–æ—Å—Ç—É–ø–Ω—ñ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –¥–ª—è –æ–±—Ä–∞–Ω–æ–≥–æ –∫–ª–∞—Å—É
        available_images = load_images_from_folder(folder_path, test_class, 100)  # –ë–µ—Ä–µ–º–æ –±–∞–≥–∞—Ç–æ
        if available_images:
            image_options = [f"{i + 1}: {filename}" for i, (_, filename) in enumerate(available_images)]
            selected_image = st.selectbox("–û–±–µ—Ä—ñ—Ç—å –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è:", image_options)
            test_image_idx = image_options.index(selected_image) + 1
        else:
            st.error(f"–ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ –∑–æ–±—Ä–∞–∂–µ–Ω—å –¥–ª—è –∫–ª–∞—Å—É {test_class}")
            test_image_idx = 1

        if st.button("–ü—Ä–æ–≤–µ—Å—Ç–∏ —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è") and available_images:
            if len(available_images) >= test_image_idx:
                pil_image, filename = available_images[test_image_idx - 1]

                try:
                    image_array = np.array(pil_image.convert('L'))
                    absolute_vector, normalized_vector, binary_image = extract_features(image_array, grid_size)
                    grid_image = create_grid_image(binary_image, grid_size)

                    # –ö–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—è
                    predicted_class, scores = st.session_state.perceptron_system.predict(normalized_vector)

                    # –í—ñ–¥–æ–±—Ä–∞–∂–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
                    col1, col2 = st.columns(2)
                    with col1:
                        st.image(pil_image, caption=f"–¢–µ—Å—Ç–æ–≤–µ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è: {filename}", use_column_width=True)
                    with col2:
                        st.image(grid_image, caption=f"–°–µ–≥–º–µ–Ω—Ç–∞—Ü—ñ—è ({grid_size})", use_column_width=True)

                    st.write("### –†–µ–∑—É–ª—å—Ç–∞—Ç –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó:")

                    # –í–∏–∑–Ω–∞—á–∞—î–º–æ –ø—Ä–∞–≤–∏–ª—å–Ω—ñ—Å—Ç—å –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó
                    is_correct = predicted_class == test_class

                    if is_correct:
                        st.success(f"**‚úì –ü—Ä–∞–≤–∏–ª—å–Ω–æ!** –°–∏—Å—Ç–µ–º–∞ –≤–∏–∑–Ω–∞—á–∏–ª–∞ —è–∫: **{predicted_class}**")
                    else:
                        st.error(f"**‚úó –ü–æ–º–∏–ª–∫–∞!** –°–ø—Ä–∞–≤–∂–Ω—ñ–π –∫–ª–∞—Å: {test_class}, –°–∏—Å—Ç–µ–º–∞ –≤–∏–∑–Ω–∞—á–∏–ª–∞: {predicted_class}")

                    st.write("**–ë–∞–ª–∏ –ø–µ—Ä—Ü–µ–ø—Ç—Ä–æ–Ω—ñ–≤:**")
                    class_names = ['–ö–≤–∞–¥—Ä–∞—Ç', '–ö–æ–ª–æ', '–†–æ–º–±']
                    for cls, score in zip(class_names, scores):
                        emphasis = "**" if cls == predicted_class else ""
                        st.write(f"- {emphasis}{cls}: {score:.4f}{emphasis}")

                    st.write("**–ê–±—Å–æ–ª—é—Ç–Ω–∏–π –≤–µ–∫—Ç–æ—Ä –æ–∑–Ω–∞–∫:**", absolute_vector)
                    st.write("**–ù–æ—Ä–º–æ–≤–∞–Ω–∏–π –≤–µ–∫—Ç–æ—Ä –æ–∑–Ω–∞–∫:**", [f"{val:.6f}" for val in normalized_vector])

                except Exception as e:
                    st.error(f"–ü–æ–º–∏–ª–∫–∞ –æ–±—Ä–æ–±–∫–∏ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è: {str(e)}")

        # –°–ø–æ—Å—ñ–± 2: –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è
        st.subheader("–¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è –Ω–∞ –Ω–æ–≤–æ–º—É –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—ñ")
        test_file = st.file_uploader("–û–±–µ—Ä—ñ—Ç—å —Ç–µ—Å—Ç–æ–≤–µ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è",
                                     type=["bmp", ".png", ".jpg", ".jpeg"],
                                     key="test_uploader")

        if test_file:
            try:
                image_bytes = test_file.read()
                pil_image = Image.open(io.BytesIO(image_bytes))
                image_array = np.array(pil_image.convert('L'))

                absolute_vector, normalized_vector, binary_image = extract_features(image_array, grid_size)
                grid_image = create_grid_image(binary_image, grid_size)

                # –ö–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—è
                predicted_class, scores = st.session_state.perceptron_system.predict(normalized_vector)

                # –í—ñ–¥–æ–±—Ä–∞–∂–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
                col1, col2 = st.columns(2)
                with col1:
                    st.image(pil_image, caption="–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–µ —Ç–µ—Å—Ç–æ–≤–µ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è", use_column_width=True)
                with col2:
                    st.image(grid_image, caption=f"–°–µ–≥–º–µ–Ω—Ç–∞—Ü—ñ—è ({grid_size})", use_column_width=True)

                st.write("### –†–µ–∑—É–ª—å—Ç–∞—Ç –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó:")
                st.success(f"**–°–∏—Å—Ç–µ–º–∞ –≤–∏–∑–Ω–∞—á–∏–ª–∞ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è —è–∫: {predicted_class}**")

                st.write("**–ë–∞–ª–∏ –ø–µ—Ä—Ü–µ–ø—Ç—Ä–æ–Ω—ñ–≤:**")
                class_names = ['–ö–≤–∞–¥—Ä–∞—Ç', '–ö–æ–ª–æ', '–†–æ–º–±']
                for cls, score in zip(class_names, scores):
                    emphasis = "**" if cls == predicted_class else ""
                    st.write(f"- {emphasis}{cls}: {score:.4f}{emphasis}")

                st.write("**–ê–±—Å–æ–ª—é—Ç–Ω–∏–π –≤–µ–∫—Ç–æ—Ä –æ–∑–Ω–∞–∫:**", absolute_vector)
                st.write("**–ù–æ—Ä–º–æ–≤–∞–Ω–∏–π –≤–µ–∫—Ç–æ—Ä –æ–∑–Ω–∞–∫:**", [f"{val:.6f}" for val in normalized_vector])

            except Exception as e:
                st.error(f"–ü–æ–º–∏–ª–∫–∞ –æ–±—Ä–æ–±–∫–∏ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è: {str(e)}")



# –°—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º–∏
st.sidebar.header("–°—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º–∏")
if st.session_state.perceptron_system.trained:
    st.sidebar.success("‚úÖ –°–∏—Å—Ç–µ–º–∞ –Ω–∞–≤—á–µ–Ω–∞")
    st.sidebar.write(f"–†–æ–∑–º—ñ—Ä–Ω—ñ—Å—Ç—å –æ–∑–Ω–∞–∫: {st.session_state.perceptron_system.feature_size}")
else:
    st.sidebar.warning("‚è≥ –°–∏—Å—Ç–µ–º–∞ –Ω–µ –Ω–∞–≤—á–µ–Ω–∞")

for class_name in ['–ö–≤–∞–¥—Ä–∞—Ç', '–ö–æ–ª–æ', '–†–æ–º–±']:
    count = len(st.session_state.perceptron_system.training_data[class_name])
    status = "‚úÖ" if count > 0 else "‚ùå"
    st.sidebar.write(f"{status} {class_name}: {count} –∑—Ä–∞–∑–∫—ñ–≤")